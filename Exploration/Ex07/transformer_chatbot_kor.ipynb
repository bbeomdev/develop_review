{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d61d761",
   "metadata": {},
   "source": [
    "# 트랜스포머로 한국어 챗봇을 만들어 보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbaf49e",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f59a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19cf10",
   "metadata": {},
   "source": [
    "## 데이터 가져오기\n",
    "\n",
    "\n",
    "https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de2811c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ChatbotData .csv'   ChatbotData.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159caf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "0                       12시 땡!                하루가 또 가네요.\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.\n",
       "...                        ...                       ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[11823 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.environ.get(\"HOME\") + \"/aiffel/transformer_chatbot/data/ChatbotData.csv\"\n",
    "df_data = pd.read_csv(data_path)\n",
    "df_data = df_data[['Q','A']]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19427f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3e532",
   "metadata": {},
   "source": [
    "결측치는 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a34e15",
   "metadata": {},
   "source": [
    "Q와 A가 모두 중복인 경우 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4505c9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>결혼이나 하지 왜 자꾸 나한테 화 내냐구!</td>\n",
       "      <td>힘들겠네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>결혼이나 하지 왜 자꾸 나한테 화 내냐구!</td>\n",
       "      <td>힘들겠네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>고백하고 후회하면 어떡하지</td>\n",
       "      <td>후회는 후회를 낳을뿐이에요. 용기 내세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>고백하고 후회하면 어떡하지</td>\n",
       "      <td>후회는 후회를 낳을뿐이에요. 용기 내세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>공부는 내 체질이 아닌 것 같아</td>\n",
       "      <td>확신이 없나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>회사 사람들이 아직도 불편해</td>\n",
       "      <td>회사에는 동료가 있을 뿐이에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>회사에는 왜 친구 같은 사람이 없을까</td>\n",
       "      <td>회사는 친구 사귀는 곳이 아니에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>회사에는 왜 친구 같은 사람이 없을까</td>\n",
       "      <td>회사는 친구 사귀는 곳이 아니에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>후련하달까</td>\n",
       "      <td>후련하니 다행이에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>후련하달까</td>\n",
       "      <td>후련하니 다행이에요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Q                        A\n",
       "152   결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.\n",
       "5527  결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.\n",
       "189            고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.\n",
       "5537           고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.\n",
       "226         공부는 내 체질이 아닌 것 같아                확신이 없나봐요.\n",
       "...                       ...                      ...\n",
       "8780          회사 사람들이 아직도 불편해        회사에는 동료가 있을 뿐이에요.\n",
       "5232     회사에는 왜 친구 같은 사람이 없을까      회사는 친구 사귀는 곳이 아니에요.\n",
       "8782     회사에는 왜 친구 같은 사람이 없을까      회사는 친구 사귀는 곳이 아니에요.\n",
       "5246                    후련하달까              후련하니 다행이에요.\n",
       "8789                    후련하달까              후련하니 다행이에요.\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df_data[df_data.duplicated( keep=False)]\n",
    "duplicates.sort_values(by=['Q','A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606932b",
   "metadata": {},
   "source": [
    "Q,A 모두 중복인 데이터가 73개 존재한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98547681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q와 A 모두 중복인 경우 마지막 행을 drop\n",
    "df_unique = df_data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d58409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Q, A]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "df_unique[df_unique.duplicated( keep=False)].sort_values(by=['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd7584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전:  (11823, 2)\n",
      "중복 제거 후:  (11750, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"중복 제거 전: \",df_data.shape)\n",
    "print(\"중복 제거 후: \",df_unique.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d056f",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "\n",
    "- 영문자열도 그대로 사용하기 위해 소문자로 변경\n",
    "- 단어와 구두점 사이 거리 두기(구두점 그대로 사용)\n",
    "- 연속된 공백 -> 하나의 공백\n",
    "- (a-z, A-Z,0-9, 가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체 **숫자, 한글 추가**\n",
    "- 양쪽 공백 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f3ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "    sentence = sentence.lower().strip()    \n",
    "\n",
    "    # 단어와 구두점 사이 거리 두기\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "    # 연속된 공백 -> 하나의 공백\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z, 0-9, 가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9가-힣\\.\\?\\!\\,]', ' ', sentence)\n",
    "    \n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36e26e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7172c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['Q'] = df_unique['Q'].apply(preprocess_sentence)\n",
    "df_preprocessed['A'] = df_unique['A'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97db0f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡 !</td>\n",
       "      <td>하루가 또 가네요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임 .</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임 .</td>\n",
       "      <td>훔쳐보는 거 티나나봐요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남 .</td>\n",
       "      <td>설렜겠어요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까 ?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Q                          A\n",
       "0                       12시 땡 !                하루가 또 가네요 .\n",
       "1                   1지망 학교 떨어졌어                 위로해 드립니다 .\n",
       "2                  3박4일 놀러가고 싶다               여행은 언제나 좋죠 .\n",
       "3               3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠 .\n",
       "4                       ppl 심하네                눈살이 찌푸려지죠 .\n",
       "...                         ...                        ...\n",
       "11818           훔쳐보는 것도 눈치 보임 .        티가 나니까 눈치가 보이는 거죠 !\n",
       "11819           훔쳐보는 것도 눈치 보임 .             훔쳐보는 거 티나나봐요 .\n",
       "11820              흑기사 해주는 짝남 .                    설렜겠어요 .\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까 ?  잘 헤어질 수 있는 사이 여부인 거 같아요 .\n",
       "11822                힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요 .\n",
       "\n",
       "[11750 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71db770",
   "metadata": {},
   "source": [
    "2\t3박4일 놀러가고 싶다\t여행은 언제나 좋죠 .  \n",
    "3\t3박4일 정도 놀러가고 싶다\t여행은 언제나 좋죠 .  \n",
    "  \n",
    "  \n",
    "11818\t훔쳐보는 것도 눈치 보임 .\t티가 나니까 눈치가 보이는 거죠 !    \n",
    "\n",
    "11819\t훔쳐보는 것도 눈치 보임 .\t훔쳐보는 거 티나나봐요 .  \n",
    "  \n",
    "**의미가 비슷한 행에 대해서는 어떻게 처리해야 할지 고민됨** => *Q로만 중복 제거, A로만 중복 제거 (언어의 미묘한 어감, 어투 차이에 대한 정보를 잃지 않을까?)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e6a696",
   "metadata": {},
   "source": [
    "Numpy 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5e0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_preprocessed['Q'].values\n",
    "answers = df_preprocessed['A'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27e10346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11750,)\n",
      "<class 'numpy.ndarray'>\n",
      "12시 땡 !\n",
      "(11750,)\n",
      "<class 'numpy.ndarray'>\n",
      "하루가 또 가네요 .\n"
     ]
    }
   ],
   "source": [
    "print(questions.shape)\n",
    "print(type(questions))\n",
    "print(questions[0])\n",
    "print(answers.shape)\n",
    "print(type(answers))\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4edff",
   "metadata": {},
   "source": [
    "## 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3703f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# SubwordTextEncoderfh 토크나이징, questions와 answers를 더한 말뭉치를 기반으로 학습하여 토크나이징\n",
    "# 토큰의 갯수는 2**13 = 8192개 를 만들도록 시도\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions+answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa36d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_token, end_token 추가; 위에서 8192[0~8191]개의 토큰이 생성을 시도했고, \n",
    "# 그 다음 인텍스로 start_token, end_token을 지정\n",
    "# []를 추가하는 이유? 토큰 시퀀스와 +연산으로 붙이기 편하게 하기 위해(리스트 합)\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8da41616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN:  [8318]\n",
      "END_TOKEN:  [8319]\n"
     ]
    }
   ],
   "source": [
    "# 2**13개 토큰 시도 결과로 8318개 만들어짐\n",
    "print(\"START_TOKEN: \",START_TOKEN)\n",
    "print(\"END_TOKEN: \", END_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8660cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320\n"
     ]
    }
   ],
   "source": [
    "# 단어장 크기 설정\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b157b708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5821, 605, 2491, 4166]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2682, 7632, 9, 6351, 94, 1]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 확인, 인코딩 확인\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06dcbe",
   "metadata": {},
   "source": [
    "### 문장 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "524c58da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최소 길이 : 1\n",
      "질문의 최대 길이 : 16\n",
      "질문의 평균 길이 : 3.9406808510638296\n",
      "답변의 최소 길이 : 1\n",
      "답변의 최대 길이 : 24\n",
      "답변의 평균 길이 : 4.716595744680851\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 혼란한 matplotlib 코드 -> 객체지향적으로 바꿔야 함\n",
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "questions_len= [len(s.split()) for s in questions ]\n",
    "answers_len = [len(s.split()) for s in answers ]\n",
    "\n",
    "print('질문의 최소 길이 : {}'.format(np.min(questions_len)))\n",
    "print('질문의 최대 길이 : {}'.format(np.max(questions_len)))\n",
    "print('질문의 평균 길이 : {}'.format(np.mean(questions_len)))\n",
    "print('답변의 최소 길이 : {}'.format(np.min(answers_len)))\n",
    "print('답변의 최대 길이 : {}'.format(np.max(answers_len)))\n",
    "print('답변의 평균 길이 : {}'.format(np.mean(answers_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(questions_len)\n",
    "plt.title('Questions')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(answers_len)\n",
    "plt.title('Answers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cb592f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "424ff9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MAX_LENGTH = 8\n",
    "A_MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e1e5a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.977872340425532\n",
      "전체 샘플 중 길이가 10 이하인 샘플의 비율: 0.9853617021276596\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(Q_MAX_LENGTH, questions)\n",
    "below_threshold_len(A_MAX_LENGTH, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b95c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479ec3c",
   "metadata": {},
   "source": [
    "**여기 틀림, 분포 확인은 문자열을 했는데, 아래서는 토큰 갯수로 필터링하기 때문에 틀림** => 나중에 고쳐야 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb6f93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a054c",
   "metadata": {},
   "source": [
    "질문은 8, 답변은 10으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07c84cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로 인코딩 & q_max_len=8, a_max_len=10 & 패딩 작업\n",
    "def prepare_tokenized_sequences(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # start_token, end_token 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # q_max_len=8, a_max_len=10 데이터만 사용\n",
    "        if len(sentence1) <= Q_MAX_LENGTH and len(sentence2) <= A_MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # q -> 8로 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=Q_MAX_LENGTH, padding='post')\n",
    "    # a -> 10으로 패딩\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=A_MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd0ac29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8320\n",
      "필터링 후의 질문 샘플 개수: 7404\n",
      "필터링 후의 답변 샘플 개수: 7404\n"
     ]
    }
   ],
   "source": [
    "questions, answers = prepare_tokenized_sequences(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593cdcb",
   "metadata": {},
   "source": [
    "데이터 수가 적은 편인것 같음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4d006",
   "metadata": {},
   "source": [
    "데이터 형태 정리\n",
    "- 인코더 input: sos + ~ + eos\n",
    "- 디코더 input: sos + ~\n",
    "- 디코더 output: ~ + eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b182df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번에 모델에 입력될 데이터 샘플 수: 64개를 한 묶음으로 보고 병렬처리\n",
    "BATCH_SIZE = 64\n",
    "# 셔플을 위한 버퍼 크기 전체 데이터 중 BUFFER_SIZE만큼 메모리에 올려서 셔플하겠다는 것; 메모리 사용량 관리 필요\n",
    "# 총 데이터가 7404개 정도라...그냥 섞는 메모리 공간을 좀 크게 함.\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()  # 처음에 메모리에 로딩하고, 이후부터 디스크 I/O 없이 하겠다.\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)   # 섞어\n",
    "dataset = dataset.batch(BATCH_SIZE)      # 배치사이즈로 배치 묶음 만들어\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)    # 다음 배치를 백그라운드에서 미리 준비해서 훈련이 끊기지 않도록 함. AUTOTUNE은 TensorFlow가 최적의 prefetch 양을 자동으로 조절해줌 → 성능 최적화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce635366",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "트랜스포머: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9890cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    위치 정보를 구성.\n",
    "    임베딩벡터 + '위치정보벡터'\n",
    "    위치 간 상대적 거리 정보를 담을 수 있어야 함\n",
    "    벡터 차원이 클수록 다양한 위치 관계를 구별할 수 있어야 함\n",
    "    다양한 주파수(다양한 거리)를 표현해야 함   \n",
    "    \n",
    "    하나의 벡터의 차원마다 주파수가 다르고,\n",
    "    단어 벡터의 같은 요소 차원(index)은 같은 주파수를 가짐 -> position에 따라 다른 값을 가짐\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    \n",
    "    # sin, cos 인자로 들어갈 angle 구함\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model,\n",
    "        )\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, : tf.shape(inputs)[1], :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08dfa570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"\n",
    "    query와 key의 내적으로 유사도를 구해 -> 행렬로 나옴(셀프어텐션에서만 정사각행렬임)\n",
    "    코사인 유사도랑 비슷함\n",
    "    소프트맥스가 너무 커지지 않기 위해 루트(차원)으로 나누어 줌\n",
    "    소프트맥스를 통과하고 V를 행렬곱\n",
    "    \"\"\"\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += mask * -1e9\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a43b891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    어텐션을 차원 그룹으로 나누어서 병렬로 수행\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # 하나의 입력으로 부터 3개의 표현을 뽑아내기 위해 각각 다른 dense를 사용\n",
    "        # 입력에 대해서 각각 다른 Dense layer를 통과시켜 서로 다른 관점의 벡터로 선형변환 시킴\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = (\n",
    "            inputs[\"query\"],\n",
    "            inputs[\"key\"],\n",
    "            inputs[\"value\"],\n",
    "            inputs[\"mask\"],\n",
    "        )\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        \n",
    "        # (batch_size, num_heads, seq_len_q, depth) -> (batch_size, seq_len_q, num_heads, depth)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b262ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩이 어텐션 계산이나 손실 계산에 영향을 주지 않도록 마스킹\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26537a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더에서 사용. Q, K 유사도 계산에서, 현재보다 미래 위치 토큰을 가리지 위해 사용.(예측해야 되니까)\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b28e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")(\n",
    "        {\"query\": inputs, \"key\": inputs, \"value\": inputs, \"mask\": padding_mask}\n",
    "    )\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c34e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(Q_MAX_LENGTH, d_model)(\n",
    "        embeddings\n",
    "    )  \n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bd42214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(\n",
    "        inputs={\n",
    "            \"query\": inputs,\n",
    "            \"key\": inputs,\n",
    "            \"value\": inputs,\n",
    "            \"mask\": look_ahead_mask,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(\n",
    "        inputs={\n",
    "            \"query\": attention1,\n",
    "            \"key\": enc_outputs,\n",
    "            \"value\": enc_outputs,\n",
    "            \"mask\": padding_mask,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(\n",
    "        attention2 + attention1\n",
    "    )\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a290d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(A_MAX_LENGTH, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"decoder_layer_{}\".format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eafbe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(\n",
    "    vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"enc_padding_mask\"\n",
    "    )(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None), name=\"look_ahead_mask\"\n",
    "    )(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"dec_padding_mask\"\n",
    "    )(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7600ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    13727744    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    20037632    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8320)   4268160     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,033,536\n",
      "Trainable params: 38,033,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2aeabd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다.\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, A_MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=\"none\"\n",
    "    )(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d606d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률을 train step에 따라 변화를 줌\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57b2f943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 커스텀한 학습률 시각화, step_num에 따라 달라짐\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd3fbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, A_MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfe9d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 25s 79ms/step - loss: 5.2558 - accuracy: 0.0888\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 4.3516 - accuracy: 0.1528\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 3.7465 - accuracy: 0.2144\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 3.5029 - accuracy: 0.2171\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 9s 81ms/step - loss: 3.3624 - accuracy: 0.2225\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 3.2638 - accuracy: 0.2262\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 3.1842 - accuracy: 0.2299\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 3.0921 - accuracy: 0.2355\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 2.9756 - accuracy: 0.2429\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 2.8270 - accuracy: 0.2534\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 2.6455 - accuracy: 0.2674\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 2.4479 - accuracy: 0.2829\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 2.2396 - accuracy: 0.3028\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 2.0271 - accuracy: 0.3259\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 9s 81ms/step - loss: 1.8011 - accuracy: 0.3541\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 1.5843 - accuracy: 0.3842\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 1.3573 - accuracy: 0.4207\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 1.1470 - accuracy: 0.4533\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.9567 - accuracy: 0.4876\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.7891 - accuracy: 0.5156\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.6481 - accuracy: 0.5382\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.5410 - accuracy: 0.5571\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.4454 - accuracy: 0.5745\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.3809 - accuracy: 0.5854\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.3257 - accuracy: 0.5948\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2895 - accuracy: 0.6004\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2618 - accuracy: 0.6045\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2471 - accuracy: 0.6057\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2291 - accuracy: 0.6074\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.2197 - accuracy: 0.6101\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2177 - accuracy: 0.6094\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.2135 - accuracy: 0.6096\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2111 - accuracy: 0.6097\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2112 - accuracy: 0.6085\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.2031 - accuracy: 0.6104\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.1948 - accuracy: 0.6120\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.1741 - accuracy: 0.6172\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.1554 - accuracy: 0.6219\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.1565 - accuracy: 0.6207\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.1373 - accuracy: 0.6260\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.1253 - accuracy: 0.6291\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.1261 - accuracy: 0.6291\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 9s 81ms/step - loss: 0.1100 - accuracy: 0.6337\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.1048 - accuracy: 0.6346\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0983 - accuracy: 0.6364\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0997 - accuracy: 0.6364\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0803 - accuracy: 0.6413\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0887 - accuracy: 0.6390\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0830 - accuracy: 0.6400\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0748 - accuracy: 0.6426\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0763 - accuracy: 0.6430\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0683 - accuracy: 0.6443\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0682 - accuracy: 0.6440\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0605 - accuracy: 0.6457\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0602 - accuracy: 0.6465\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0582 - accuracy: 0.6466\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0550 - accuracy: 0.6480\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0574 - accuracy: 0.6471\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0478 - accuracy: 0.6498\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0479 - accuracy: 0.6497\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0481 - accuracy: 0.6492\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0443 - accuracy: 0.6500\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0426 - accuracy: 0.6509\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.0436 - accuracy: 0.6506\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0410 - accuracy: 0.6515\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0404 - accuracy: 0.6514\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0424 - accuracy: 0.6508\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0338 - accuracy: 0.6534\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0340 - accuracy: 0.6535\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.0400 - accuracy: 0.6517\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0361 - accuracy: 0.6524\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0341 - accuracy: 0.6530\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0327 - accuracy: 0.6535\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0326 - accuracy: 0.6535\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0299 - accuracy: 0.6544\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0327 - accuracy: 0.6537\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 9s 81ms/step - loss: 0.0284 - accuracy: 0.6546\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0290 - accuracy: 0.6544\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0287 - accuracy: 0.6544\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0284 - accuracy: 0.6543\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0272 - accuracy: 0.6550\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0268 - accuracy: 0.6553\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0278 - accuracy: 0.6547\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0289 - accuracy: 0.6546\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0247 - accuracy: 0.6555\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0241 - accuracy: 0.6555\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0255 - accuracy: 0.6554\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0218 - accuracy: 0.6563\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0208 - accuracy: 0.6564\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0235 - accuracy: 0.6560\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0194 - accuracy: 0.6570\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0236 - accuracy: 0.6559\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0227 - accuracy: 0.6561\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0212 - accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0222 - accuracy: 0.6564\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0189 - accuracy: 0.6568\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.0203 - accuracy: 0.6564\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0205 - accuracy: 0.6566\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.0190 - accuracy: 0.6571\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.0195 - accuracy: 0.6570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7a5e8d5ed4f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19425f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0\n",
    "    )\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(A_MAX_LENGTH):\n",
    "        # 디코더는 최대 A_MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39ac3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size]\n",
    "    )\n",
    "\n",
    "    print(\"입력 : {}\".format(sentence))\n",
    "    print(\"출력 : {}\".format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8062f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 여행가고 싶어\n",
      "출력 : 계획을 세워보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'계획을 세워보세요 .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"여행가고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8563bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 쉬고 싶어\n",
      "출력 : 내려 놓으세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내려 놓으세요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"쉬고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b80b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사하고 싶어\n",
      "출력 : 얼른 알아보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'얼른 알아보세요 .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사하고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78d46f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사만세\n",
      "출력 : 얼른 주무세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'얼른 주무세요 .'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사만세\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8be5d8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사는게 좋을까?\n",
      "출력 : 진정하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'진정하세요 .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사는게 좋을까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d05eadbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_925/4201271172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"퇴사해도 될까?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_925/2032962927.py\u001b[0m in \u001b[0;36msentence_generation\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_925/1415062486.py\u001b[0m in \u001b[0;36mdecoder_inference\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_MAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 디코더는 최대 A_MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_925/320024709.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "sentence_generation(\"퇴사해도 될까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2c3ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 회사 다니기 싫어\n",
      "출력 : 파이팅 !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'파이팅 !'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"회사 다니기 싫어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbb36cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 회사 다니고 싶어\n",
      "출력 : 현재를 즐기세요 !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'현재를 즐기세요 !'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"회사 다니고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04883102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : kiwi\n",
      "출력 : 정신 차리세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'정신 차리세요 .'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"kiwi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2987f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 포도 먹고 싶다\n",
      "출력 : 저랑 한잔 해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저랑 한잔 해요 .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"포도 먹고 싶다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4213981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 책이 2원이야\n",
      "출력 : 그럴 시기에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그럴 시기에요 .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"책이 2원이야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ed88685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 또 체했네 아휴\n",
      "출력 : 또 다시 이땐 생각을 차리세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'또 다시 이땐 생각을 차리세요 .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"또 체했네 아휴\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8e878",
   "metadata": {},
   "source": [
    "# 회고\n",
    "충분한 epoch으로 학습해야 한다.  \n",
    "질문 토큰 갯수를 너무 적게 해서, 긴 문장을 질문하면 에러가 발생한다.  \n",
    "더 많은 데이터를 넣으면 어떻게 될지 궁금하다.    \n",
    "데이터가 없는 문장에 대해서는 좋은 답변이 나오지 않는 것 같다   \n",
    "숫자, 영어에 대한 처리도 가능한 것 같다   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1898708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
