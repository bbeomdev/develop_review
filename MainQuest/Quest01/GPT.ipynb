{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f87419",
   "metadata": {},
   "source": [
    "# GPT 모델을 구성해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe2fec",
   "metadata": {},
   "source": [
    "## Transformer와 비교해 변경이 필요한 부분 서술\n",
    "\n",
    "- GPT 모델에서는 Decoder만 사용하므로, Encoder의 모든 부분은 삭제한다.\n",
    "- Decoder의 input에서 positional encoding을 positional embedding으로 변경한다.(positional encoding은 sin, cos으로 고정, positiona embedding은 학습 가능하다)\n",
    "- Encoder가 없으므로 encoder-decoder attension layer를 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63be03",
   "metadata": {},
   "source": [
    "model summary. \n",
    "![summary](./model_summary.png)\n",
    "model fit. \n",
    "![fit](./model_fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be69d2",
   "metadata": {},
   "source": [
    "## 모델의 입력 형태에 맞게 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cb8b5",
   "metadata": {},
   "source": [
    "### import labrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b507c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f6069",
   "metadata": {},
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01a5a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>요즘 드라마가 땡겨</td>\n",
       "      <td>저도 드라마 좋아해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>사랑하는 사람이랑 결혼하고싶어</td>\n",
       "      <td>언젠가 그런 사람이 당신 옆에 있을거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>이별 중독</td>\n",
       "      <td>슬픈 단어네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>저는 개인적으로 따로 연락하자는분들.</td>\n",
       "      <td>부담스러운가봅니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>매번 왜 이렇게 남는게 후회인지 모르겠네 ㅎㅎ</td>\n",
       "      <td>모든 일에는 후회가 남기 마련인가봐요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Q                        A\n",
       "3476                 요즘 드라마가 땡겨             저도 드라마 좋아해요.\n",
       "9962           사랑하는 사람이랑 결혼하고싶어  언젠가 그런 사람이 당신 옆에 있을거예요.\n",
       "7443                      이별 중독                 슬픈 단어네요.\n",
       "7944       저는 개인적으로 따로 연락하자는분들.               부담스러운가봅니다.\n",
       "6270  매번 왜 이렇게 남는게 후회인지 모르겠네 ㅎㅎ    모든 일에는 후회가 남기 마련인가봐요."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.environ.get(\"HOME\") + \"/aiffel/transformer_chatbot/data/ChatbotData.csv\"\n",
    "df_data = pd.read_csv(data_path)\n",
    "df_data = df_data[['Q','A']]\n",
    "df_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa300f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d414a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>결혼이나 하지 왜 자꾸 나한테 화 내냐구!</td>\n",
       "      <td>힘들겠네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>결혼이나 하지 왜 자꾸 나한테 화 내냐구!</td>\n",
       "      <td>힘들겠네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>고백하고 후회하면 어떡하지</td>\n",
       "      <td>후회는 후회를 낳을뿐이에요. 용기 내세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>고백하고 후회하면 어떡하지</td>\n",
       "      <td>후회는 후회를 낳을뿐이에요. 용기 내세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>공부는 내 체질이 아닌 것 같아</td>\n",
       "      <td>확신이 없나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>회사 사람들이 아직도 불편해</td>\n",
       "      <td>회사에는 동료가 있을 뿐이에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>회사에는 왜 친구 같은 사람이 없을까</td>\n",
       "      <td>회사는 친구 사귀는 곳이 아니에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>회사에는 왜 친구 같은 사람이 없을까</td>\n",
       "      <td>회사는 친구 사귀는 곳이 아니에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>후련하달까</td>\n",
       "      <td>후련하니 다행이에요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>후련하달까</td>\n",
       "      <td>후련하니 다행이에요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Q                        A\n",
       "152   결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.\n",
       "5527  결혼이나 하지 왜 자꾸 나한테 화 내냐구!                   힘들겠네요.\n",
       "189            고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.\n",
       "5537           고백하고 후회하면 어떡하지  후회는 후회를 낳을뿐이에요. 용기 내세요.\n",
       "226         공부는 내 체질이 아닌 것 같아                확신이 없나봐요.\n",
       "...                       ...                      ...\n",
       "8780          회사 사람들이 아직도 불편해        회사에는 동료가 있을 뿐이에요.\n",
       "5232     회사에는 왜 친구 같은 사람이 없을까      회사는 친구 사귀는 곳이 아니에요.\n",
       "8782     회사에는 왜 친구 같은 사람이 없을까      회사는 친구 사귀는 곳이 아니에요.\n",
       "5246                    후련하달까              후련하니 다행이에요.\n",
       "8789                    후련하달까              후련하니 다행이에요.\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df_data[df_data.duplicated( keep=False)]\n",
    "duplicates.sort_values(by=['Q','A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e6232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q와 A 모두 중복인 경우 마지막 행을 drop\n",
    "df_unique = df_data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34b77b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Q, A]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "df_unique[df_unique.duplicated( keep=False)].sort_values(by=['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb16dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전:  (11823, 2)\n",
      "중복 제거 후:  (11750, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"중복 제거 전: \",df_data.shape)\n",
    "print(\"중복 제거 후: \",df_unique.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f3de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "    sentence = sentence.lower().strip()    \n",
    "\n",
    "    # 단어와 구두점 사이 거리 두기\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "    # 연속된 공백 -> 하나의 공백\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z, 0-9, 가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9가-힣\\.\\?\\!\\,]', ' ', sentence)\n",
    "    \n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b895b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0183178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed['Q'] = df_unique['Q'].apply(preprocess_sentence)\n",
    "df_preprocessed['A'] = df_unique['A'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa29e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡 !</td>\n",
       "      <td>하루가 또 가네요 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q             A\n",
       "0          12시 땡 !   하루가 또 가네요 .\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다 .\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠 .\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠 .\n",
       "4          ppl 심하네   눈살이 찌푸려지죠 ."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1be523",
   "metadata": {},
   "source": [
    "numpy 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555b00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_preprocessed['Q'].values\n",
    "answers = df_preprocessed['A'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4dada43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11750,)\n",
      "<class 'numpy.ndarray'>\n",
      "12시 땡 !\n",
      "(11750,)\n",
      "<class 'numpy.ndarray'>\n",
      "하루가 또 가네요 .\n"
     ]
    }
   ],
   "source": [
    "print(questions.shape)\n",
    "print(type(questions))\n",
    "print(questions[0])\n",
    "print(answers.shape)\n",
    "print(type(answers))\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d499ecf",
   "metadata": {},
   "source": [
    "### tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9101c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# SubwordTextEncoderfh 토크나이징, questions와 answers를 더한 말뭉치를 기반으로 학습하여 토크나이징\n",
    "# 토큰의 갯수는 2**13 = 8192개 를 만들도록 시도\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions+answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6be534",
   "metadata": {},
   "source": [
    "입력을 시퀀스 형태로 만들기 위해 DELIMETER 토큰을 추가한다   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82091c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_token, end_token 추가; 위에서 8192[0~8191]개의 토큰이 생성을 시도했고, \n",
    "# 그 다음 인텍스로 start_token, end_token을 지정\n",
    "# []를 추가하는 이유? 토큰 시퀀스와 +연산으로 붙이기 편하게 하기 위해(리스트 합)\n",
    "\n",
    "START_TOKEN, DELIMETER, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1], [tokenizer.vocab_size+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80ba888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN:  [8318]\n",
      "DELIMETER:  [8319]\n",
      "END_TOKEN:  [8320]\n"
     ]
    }
   ],
   "source": [
    "# 2**13개 토큰 시도 결과로 8318개 만들어짐\n",
    "print(\"START_TOKEN: \",START_TOKEN)\n",
    "print(\"DELIMETER: \", DELIMETER)\n",
    "print(\"END_TOKEN: \", END_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a97d5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8321\n"
     ]
    }
   ],
   "source": [
    "# 단어장 크기 설정 -> start_token, delimeter, end_token 추가\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 3\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aa37470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5821, 605, 2491, 4166]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2682, 7632, 9, 6351, 94, 1]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 확인, 인코딩 확인\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da814576",
   "metadata": {},
   "source": [
    "### 문장 길이 분포 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9eea40",
   "metadata": {},
   "source": [
    "### decoder input\n",
    "\n",
    "sos + question + delimeter + answer + eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b763b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최소 길이 : 1\n",
      "질문의 최대 길이 : 16\n",
      "질문의 평균 길이 : 3.9406808510638296\n",
      "답변의 최소 길이 : 1\n",
      "답변의 최대 길이 : 24\n",
      "답변의 평균 길이 : 4.716595744680851\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 혼란한 matplotlib 코드 -> 객체지향적으로 바꿔야 함\n",
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "questions_len= [len(s.split()) for s in questions ]\n",
    "answers_len = [len(s.split()) for s in answers ]\n",
    "\n",
    "print('질문의 최소 길이 : {}'.format(np.min(questions_len)))\n",
    "print('질문의 최대 길이 : {}'.format(np.max(questions_len)))\n",
    "print('질문의 평균 길이 : {}'.format(np.mean(questions_len)))\n",
    "print('답변의 최소 길이 : {}'.format(np.min(answers_len)))\n",
    "print('답변의 최대 길이 : {}'.format(np.max(answers_len)))\n",
    "print('답변의 평균 길이 : {}'.format(np.mean(answers_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(questions_len)\n",
    "plt.title('Questions')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(answers_len)\n",
    "plt.title('Answers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12585a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for question, answer in zip(questions, answers):\n",
    "    sequence = START_TOKEN + tokenizer.encode(question) \\\n",
    "                    + DELIMETER + tokenizer.encode(answer) \\\n",
    "                    + END_TOKEN\n",
    "    input_sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59c94754",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(seq) for seq in input_sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b02c1437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소 길이: 5\n",
      "최대 길이: 41\n",
      "평균 길이: 14.34136170212766\n",
      "중앙값 길이: 14.0\n",
      "95퍼센타일 길이: 22.0\n"
     ]
    }
   ],
   "source": [
    "print(\"최소 길이:\", np.min(sequence_lengths))\n",
    "print(\"최대 길이:\", np.max(sequence_lengths))\n",
    "print(\"평균 길이:\", np.mean(sequence_lengths))\n",
    "print(\"중앙값 길이:\", np.median(sequence_lengths))\n",
    "print(\"95퍼센타일 길이:\", np.percentile(sequence_lengths, 95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae33014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95퍼센타일 길이: 26.0\n"
     ]
    }
   ],
   "source": [
    "print(\"95퍼센타일 길이:\", np.percentile(sequence_lengths, 99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f10915",
   "metadata": {},
   "source": [
    "26으로 MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20dcb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filtered = []\n",
    "for sequence in input_sequences:\n",
    "    if len(sequence) <= 26:\n",
    "        input_filtered.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3d0f097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 전:  11750\n",
      "필터링 후:  11666\n"
     ]
    }
   ],
   "source": [
    "print(\"필터링 전: \",len(input_sequences))\n",
    "print(\"필터링 후: \", len(input_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b713e6",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "469e22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      input_sequences, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c4fe5",
   "metadata": {},
   "source": [
    "### 데이터 셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "659cf3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번에 모델에 입력될 데이터 샘플 수: 64개를 한 묶음으로 보고 병렬처리\n",
    "BATCH_SIZE = 64\n",
    "# 셔플을 위한 버퍼 크기 전체 데이터 중 BUFFER_SIZE만큼 메모리에 올려서 셔플하겠다는 것; 메모리 사용량 관리 필요\n",
    "# 총 데이터가 11750개 정도라...그냥 섞는 메모리 공간을 좀 크게 함.\n",
    "BUFFER_SIZE = 15000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'dec_inputs': input_padded[:, :-1],\n",
    "    },\n",
    "    {\n",
    "        'outputs': input_padded[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()  # 처음에 메모리에 로딩하고, 이후부터 디스크 I/O 없이 하겠다.\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)   # 섞어\n",
    "dataset = dataset.batch(BATCH_SIZE)      # 배치사이즈로 배치 묶음 만들어\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)    # 다음 배치를 백그라운드에서 미리 준비해서 훈련이 끊기지 않도록 함. AUTOTUNE은 TensorFlow가 최적의 prefetch 양을 자동으로 조절해줌 → 성능 최적화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3a281",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, max_length, embedding_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.pos_embedding = layers.Embedding(\n",
    "            input_dim=max_length,\n",
    "            output_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs: (batch_size, seq_len, embedding_dim)\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        positions = tf.range(start=0, limit=seq_len, delta=1)  # (seq_len,)\n",
    "        positions = tf.expand_dims(positions, 0)               # (1, seq_len)\n",
    "        positions = tf.tile(positions, [batch_size, 1])        # (batch_size, seq_len)\n",
    "\n",
    "        pos_embeddings = self.pos_embedding(positions)         # (batch_size, seq_len, embedding_dim)\n",
    "        return inputs + pos_embeddings                         # broadcasting-safe 덧셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b61198e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"\n",
    "    query와 key의 내적으로 유사도를 구해 -> 행렬로 나옴(셀프어텐션에서만 정사각행렬임)\n",
    "    코사인 유사도랑 비슷함\n",
    "    소프트맥스가 너무 커지지 않기 위해 루트(차원)으로 나누어 줌\n",
    "    소프트맥스를 통과하고 V를 행렬곱\n",
    "    \"\"\"\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += mask * -1e9\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9531caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    어텐션을 차원 그룹으로 나누어서 병렬로 수행\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # 하나의 입력으로 부터 3개의 표현을 뽑아내기 위해 각각 다른 dense를 사용\n",
    "        # 입력에 대해서 각각 다른 Dense layer를 통과시켜 서로 다른 관점의 벡터로 선형변환 시킴\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = (\n",
    "            inputs[\"query\"],\n",
    "            inputs[\"key\"],\n",
    "            inputs[\"value\"],\n",
    "            inputs[\"mask\"],\n",
    "        )\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        \n",
    "        # (batch_size, num_heads, seq_len_q, depth) -> (batch_size, seq_len_q, num_heads, depth)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55c37a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩이 어텐션 계산이나 손실 계산에 영향을 주지 않도록 마스킹\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcc704b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더에서 사용. Q, K 유사도 계산에서, 현재보다 미래 위치 토큰을 가리지 위해 사용.(예측해야 되니까)\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba64dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    \n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "#     padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(\n",
    "        inputs={\n",
    "            \"query\": inputs,\n",
    "            \"key\": inputs,\n",
    "            \"value\": inputs,\n",
    "            \"mask\": look_ahead_mask,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    \n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention1)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention1)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs,  look_ahead_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddbdcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    \n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 패딩 마스크\n",
    "#     padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEmbedding(MAX_LENGTH, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"decoder_layer_{}\".format(i),\n",
    "        )([outputs,  look_ahead_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs,  look_ahead_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c5494cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT(\n",
    "    vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"gpt\"\n",
    "):\n",
    "\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None), name=\"look_ahead_mask\"\n",
    "    )(dec_inputs)\n",
    "\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs,  look_ahead_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[dec_inputs], outputs=outputs, name=name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b4c8ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    23209472    dec_inputs[0][0]                 \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8321)   4268673     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,478,145\n",
      "Trainable params: 27,478,145\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 12 # 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = GPT(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2137ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다.\n",
    "# def loss_function(y_true, y_pred):\n",
    "#     y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "#     loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "#         from_logits=True, reduction=\"none\"\n",
    "#     )(y_true, y_pred)\n",
    "\n",
    "#     mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "#     loss = tf.multiply(loss, mask)\n",
    "\n",
    "#     return tf.reduce_mean(loss)\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    # y_true: (batch, seq_len)\n",
    "    # y_pred: (batch, seq_len, vocab_size)\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=\"none\"\n",
    "    )(y_true, y_pred)\n",
    "\n",
    "    # 패딩 마스킹: 0인 부분 제외\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d2359cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률을 train step에 따라 변화를 줌\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06a189f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# def accuracy(y_true, y_pred):\n",
    "#   y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "#   return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd492eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "184/184 [==============================] - 54s 130ms/step - loss: 8.0808 - accuracy: 0.0413\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 25s 136ms/step - loss: 6.7889 - accuracy: 0.1079\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 25s 135ms/step - loss: 6.2801 - accuracy: 0.1194\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 24s 132ms/step - loss: 5.9622 - accuracy: 0.1245\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 5.7566 - accuracy: 0.1281\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 5.5958 - accuracy: 0.1322\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 5.4430 - accuracy: 0.1369\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 5.3017 - accuracy: 0.1407\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 5.1478 - accuracy: 0.1448\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.9907 - accuracy: 0.1492\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.8305 - accuracy: 0.1535\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.6788 - accuracy: 0.1576\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.5370 - accuracy: 0.1613\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.3888 - accuracy: 0.1653\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.2438 - accuracy: 0.1702\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 4.1091 - accuracy: 0.1742\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 3.9732 - accuracy: 0.1801\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 3.8747 - accuracy: 0.1830\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 3.7555 - accuracy: 0.1882\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 3.6654 - accuracy: 0.1921\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 3.5927 - accuracy: 0.1953\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 3.5742 - accuracy: 0.1947\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 3.4058 - accuracy: 0.2048\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 3.4563 - accuracy: 0.2065\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 3.8861 - accuracy: 0.1780\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 3.1701 - accuracy: 0.2190\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 2.9325 - accuracy: 0.2367\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 2.8259 - accuracy: 0.2444\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 2.6792 - accuracy: 0.2576\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 2.5441 - accuracy: 0.2698\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 2.3881 - accuracy: 0.2841\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 2.2802 - accuracy: 0.2928\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 24s 132ms/step - loss: 2.1718 - accuracy: 0.3043\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 2.0733 - accuracy: 0.3143\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 2.0240 - accuracy: 0.3191\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.9951 - accuracy: 0.3218\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.8327 - accuracy: 0.3397\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.8120 - accuracy: 0.3416\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.8677 - accuracy: 0.3356\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.8101 - accuracy: 0.3433\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.8246 - accuracy: 0.3417\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.6862 - accuracy: 0.3575\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.6967 - accuracy: 0.3560\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.5962 - accuracy: 0.3673\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.6101 - accuracy: 0.3659\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 24s 132ms/step - loss: 1.5795 - accuracy: 0.3690\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.5252 - accuracy: 0.3750\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.5109 - accuracy: 0.3778\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.4475 - accuracy: 0.3860\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 24s 133ms/step - loss: 1.4335 - accuracy: 0.3873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6ffd3c076070>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7605a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(input_text):\n",
    "    input_ids = START_TOKEN + tokenizer.encode(preprocess_sentence(input_text)) + DELIMETER\n",
    "    output_sequence = tf.expand_dims(input_ids, axis=0)  # shape: (1, seq_len)\n",
    "\n",
    "    for _ in range(MAX_LENGTH):\n",
    "        predictions = model(output_sequence, training=False)\n",
    "        next_token_logits = predictions[:, -1, :]\n",
    "        predicted_id = tf.argmax(next_token_logits, axis=-1, output_type=tf.int32)\n",
    "\n",
    "        if predicted_id[0] == END_TOKEN[0]:\n",
    "            break\n",
    "\n",
    "        predicted_id = tf.expand_dims(predicted_id, axis=-1)  # shape: (1, 1)\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cb0bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size]\n",
    "    )\n",
    "\n",
    "    print(\"입력 : {}\".format(sentence))\n",
    "    print(\"출력 : {}\".format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84477696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사하고 싶어\n",
      "출력 : 퇴사하고 싶어제가 드리고 싶네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'퇴사하고 싶어제가 드리고 싶네요 .'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사하고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc238ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사만세\n",
      "출력 : 퇴사만세더 열심히 하면 좋겠어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'퇴사만세더 열심히 하면 좋겠어요 .'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사만세\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "173f287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사는게 좋을까?\n",
      "출력 : 퇴사는게 좋을까 ?좀 더 많이 다질거 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'퇴사는게 좋을까 ?좀 더 많이 다질거 같아요 .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사는게 좋을까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99f3c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴사해도 될까?\n",
      "출력 : 퇴사해도 될까 ?전혀 갈 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'퇴사해도 될까 ?전혀 갈 수 있을 거예요 .'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"퇴사해도 될까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b896cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 쉬고 싶어\n",
      "출력 : 쉬고 싶어내려 놓으세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'쉬고 싶어내려 놓으세요 .'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"쉬고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912d97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e77f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4059037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dca17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
